{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIE 1624 Assignment 1\n",
    "## Keon Young Park (1004686253)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Unzip 'classified_tweets.txt' first to begin with"
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import html\n",
    "import nltk\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "\n",
    "# !pip install tqdm\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class          id                          date     query             user  \\\n",
       "0      0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY  _TheSpecialOne_   \n",
       "1      0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY    scotthamilton   \n",
       "2      0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY         mattycus   \n",
       "3      0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          ElleCTF   \n",
       "4      0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY           Karoli   \n",
       "\n",
       "                                                text  \n",
       "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1  is upset that he can't update his Facebook by ...  \n",
       "2  @Kenichan I dived many times for the ball. Man...  \n",
       "3    my whole body feels itchy and like its on fire   \n",
       "4  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading classified_tweets.txt\n",
    "classf = pd.read_csv(\"classified_tweets.txt\")\n",
    "print(classf.shape)\n",
    "classf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3026, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>living the dream. #cameraman #camera #camerace...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>justin #trudeau's reasons for thanksgiving. to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@themadape   butt…..butt…..we’re allergic to l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2 massive explosions at peace march in #turkey...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#mulcair suggests there’s bad blood between hi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Raw\n",
       "0  living the dream. #cameraman #camera #camerace...\n",
       "1  justin #trudeau's reasons for thanksgiving. to...\n",
       "2  @themadape   butt…..butt…..we’re allergic to l...\n",
       "3  2 massive explosions at peace march in #turkey...\n",
       "4  #mulcair suggests there’s bad blood between hi..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading unclassified_tweets.txt\n",
    "unclassf = pd.read_table(\"unclassified_tweets.txt\", names = (['Raw']))\n",
    "print(unclassf.shape)\n",
    "unclassf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(665, 1)\n"
     ]
    }
   ],
   "source": [
    "# Loading provided stop_words.txt file\n",
    "stop = pd.read_table(\"stop_words.txt\", names = ['stopwords'])\n",
    "stop.head()\n",
    "print(stop.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n"
     ]
    }
   ],
   "source": [
    "# Loading stopwords(English) from NLTK package\n",
    "# Both given list of stopwords and the list from NLTK package will be used\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "\n",
    "stop_nltk = stopwords.words('english')\n",
    "print(len(stop_nltk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1. Data cleaning (30 marks)\n",
    "\n",
    "The tweets, as given, are not in a form amenable to analysis -- there is too much ‘noise’. Therefore, the first step is to “clean” the data. Design a procedure that prepares the Twitter data for analysis by satisfying the requirements below.\n",
    "\n",
    "o All html tags and attributes (i.e., /<[^>]+>/) are removed.\n",
    "\n",
    "o Html character codes (i.e., &...;) are replaced with an ASCII equivalent. o All URLs are removed.\n",
    "\n",
    "o All characters in the text are in lowercase.\n",
    "\n",
    "o All stopwords are removed. Be clear in what you consider as a stopword. o If a tweet is empty after pre-processing, it should be preserved as such."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make all character lower case first\n",
    "def lowercase(tweet):\n",
    "    tweet = tweet.lower()\n",
    "    return tweet\n",
    "\n",
    "classf['text'] = classf['text'].apply(lowercase)\n",
    "unclassf['Raw'] = unclassf[\"Raw\"].apply(lowercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove all html tags and attributes \n",
    "def clean_html_tag(tweet):\n",
    "    pattern = re.compile(r'<[^>]+>')\n",
    "    tweet = re.sub(pattern, '' , tweet)\n",
    "    return tweet\n",
    "\n",
    "classf['text'] = classf[\"text\"].apply(clean_html_tag)\n",
    "unclassf['Raw'] = unclassf[\"Raw\"].apply(clean_html_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Replace html character codes with ASCII equivalent\n",
    "def html_ascii(tweet):\n",
    "    tweet = html.unescape(tweet)\n",
    "    return tweet\n",
    "classf['text'] = classf[\"text\"].apply(html_ascii)\n",
    "unclassf['Raw'] = unclassf[\"Raw\"].apply(html_ascii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove different types of URLs\n",
    "def cleanurl(tweet):\n",
    "    pattern_1 = '\\w+\\.\\S+'\n",
    "    tweet = re.sub(pattern_1, '', tweet)\n",
    "    \n",
    "    pattern_2 = 'https?:\\/\\/\\w+\\S+' \n",
    "    tweet = re.sub(pattern_2, '', tweet)\n",
    "    \n",
    "    pattern_3 = 'https?'\n",
    "    tweet = re.sub(pattern_3, '', tweet)\n",
    "    \n",
    "    pattern_4 = 'https?:\\/\\/'\n",
    "    tweet = re.sub(pattern_4, '', tweet)\n",
    "    \n",
    "    pattern_5 = 'www\\.\\w+\\S+'\n",
    "    tweet = re.sub(pattern_5, '', tweet)\n",
    "    return tweet\n",
    "\n",
    "classf['text'] = classf[\"text\"].apply(cleanurl)\n",
    "unclassf['Raw'] = unclassf[\"Raw\"].apply(cleanurl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1. Tokenize tweets for removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing...: 100%|██████████| 200000/200000 [00:45<00:00, 4430.76it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>Cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot :// - awww, that's a bummer.  you ...</td>\n",
       "      <td>[@, switchfoot, :, //, -, awww, ,, that, 's, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his facebook by ...</td>\n",
       "      <td>[is, upset, that, he, ca, n't, update, his, fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@kenichan i dived many times for the ball. man...</td>\n",
       "      <td>[@, kenichan, i, dived, many, times, for, the,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>[my, whole, body, feels, itchy, and, like, its...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>[@, nationwideclass, no, ,, it, 's, not, behav...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class          id                          date     query             user  \\\n",
       "0      0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY  _TheSpecialOne_   \n",
       "1      0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY    scotthamilton   \n",
       "2      0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY         mattycus   \n",
       "3      0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          ElleCTF   \n",
       "4      0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY           Karoli   \n",
       "\n",
       "                                                text  \\\n",
       "0  @switchfoot :// - awww, that's a bummer.  you ...   \n",
       "1  is upset that he can't update his facebook by ...   \n",
       "2  @kenichan i dived many times for the ball. man...   \n",
       "3    my whole body feels itchy and like its on fire    \n",
       "4  @nationwideclass no, it's not behaving at all....   \n",
       "\n",
       "                                             Cleaned  \n",
       "0  [@, switchfoot, :, //, -, awww, ,, that, 's, a...  \n",
       "1  [is, upset, that, he, ca, n't, update, his, fa...  \n",
       "2  [@, kenichan, i, dived, many, times, for, the,...  \n",
       "3  [my, whole, body, feels, itchy, and, like, its...  \n",
       "4  [@, nationwideclass, no, ,, it, 's, not, behav...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Tokenize tweets of classified_tweets to remove stopwords\n",
    "## tqdm lib. shows the progress\n",
    "tqdm.pandas(desc=\"Tokenizing...\")\n",
    "classf['Cleaned'] = classf['text'].progress_apply(nltk.tokenize.word_tokenize)\n",
    "classf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing...: 100%|██████████| 3026/3026 [00:00<00:00, 3953.01it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Raw</th>\n",
       "      <th>Cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>living the dream. #cameraman #camera #camerace...</td>\n",
       "      <td>[living, the, dream, ., #, cameraman, #, camer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>justin #trudeau's reasons for thanksgiving. to...</td>\n",
       "      <td>[justin, #, trudeau, 's, reasons, for, thanksg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@themadape   butt…..butt…..we’re allergic to l...</td>\n",
       "      <td>[@, themadape, butt…..butt…..we, ’, re, allerg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2 massive explosions at peace march in #turkey...</td>\n",
       "      <td>[2, massive, explosions, at, peace, march, in,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#mulcair suggests there’s bad blood between hi...</td>\n",
       "      <td>[#, mulcair, suggests, there, ’, s, bad, blood...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Raw  \\\n",
       "0  living the dream. #cameraman #camera #camerace...   \n",
       "1  justin #trudeau's reasons for thanksgiving. to...   \n",
       "2  @themadape   butt…..butt…..we’re allergic to l...   \n",
       "3  2 massive explosions at peace march in #turkey...   \n",
       "4  #mulcair suggests there’s bad blood between hi...   \n",
       "\n",
       "                                             Cleaned  \n",
       "0  [living, the, dream, ., #, cameraman, #, camer...  \n",
       "1  [justin, #, trudeau, 's, reasons, for, thanksg...  \n",
       "2  [@, themadape, butt…..butt…..we, ’, re, allerg...  \n",
       "3  [2, massive, explosions, at, peace, march, in,...  \n",
       "4  [#, mulcair, suggests, there, ’, s, bad, blood...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Tokenize tweets of unclassified_tweets to remove stopwords\n",
    "tqdm.pandas(desc=\"Tokenizing...\")\n",
    "unclassf['Cleaned'] = unclassf['Raw'].progress_apply(nltk.tokenize.word_tokenize)\n",
    "unclassf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# After tokenizing, remove all stopwords from tokenized tweets of both Classified & Unclassified tweets\n",
    "classf['Cleaned'] = classf['Cleaned'].apply(lambda x: [item for item in x if item not in stop_nltk])\n",
    "classf['Cleaned'] = classf['Cleaned'].apply(lambda x: [item for item in x if item not in stop])\n",
    "\n",
    "unclassf['Cleaned'] = unclassf['Cleaned'].apply(lambda x: [item for item in x if item not in stop_nltk])\n",
    "unclassf['Cleaned'] = unclassf['Cleaned'].apply(lambda x: [item for item in x if item not in stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>Cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot :// - awww, that's a bummer.  you ...</td>\n",
       "      <td>[@, switchfoot, :, //, -, awww, ,, 's, bummer,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his facebook by ...</td>\n",
       "      <td>[upset, ca, n't, update, facebook, texting, mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@kenichan i dived many times for the ball. man...</td>\n",
       "      <td>[@, kenichan, dived, many, times, ball, ., man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>[whole, body, feels, itchy, like, fire]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>[@, nationwideclass, ,, 's, behaving, ., 'm, m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class          id                          date     query             user  \\\n",
       "0      0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY  _TheSpecialOne_   \n",
       "1      0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY    scotthamilton   \n",
       "2      0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY         mattycus   \n",
       "3      0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          ElleCTF   \n",
       "4      0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY           Karoli   \n",
       "\n",
       "                                                text  \\\n",
       "0  @switchfoot :// - awww, that's a bummer.  you ...   \n",
       "1  is upset that he can't update his facebook by ...   \n",
       "2  @kenichan i dived many times for the ball. man...   \n",
       "3    my whole body feels itchy and like its on fire    \n",
       "4  @nationwideclass no, it's not behaving at all....   \n",
       "\n",
       "                                             Cleaned  \n",
       "0  [@, switchfoot, :, //, -, awww, ,, 's, bummer,...  \n",
       "1  [upset, ca, n't, update, facebook, texting, mi...  \n",
       "2  [@, kenichan, dived, many, times, ball, ., man...  \n",
       "3            [whole, body, feels, itchy, like, fire]  \n",
       "4  [@, nationwideclass, ,, 's, behaving, ., 'm, m...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Raw</th>\n",
       "      <th>Cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>living the dream. #cameraman #camera #camerace...</td>\n",
       "      <td>[living, dream, ., #, cameraman, #, camera, #,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>justin #trudeau's reasons for thanksgiving. to...</td>\n",
       "      <td>[justin, #, trudeau, 's, reasons, thanksgiving...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@themadape   butt…..butt…..we’re allergic to l...</td>\n",
       "      <td>[@, themadape, butt…..butt…..we, ’, allergic, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2 massive explosions at peace march in #turkey...</td>\n",
       "      <td>[2, massive, explosions, peace, march, #, turk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#mulcair suggests there’s bad blood between hi...</td>\n",
       "      <td>[#, mulcair, suggests, ’, bad, blood, #, trude...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Raw  \\\n",
       "0  living the dream. #cameraman #camera #camerace...   \n",
       "1  justin #trudeau's reasons for thanksgiving. to...   \n",
       "2  @themadape   butt…..butt…..we’re allergic to l...   \n",
       "3  2 massive explosions at peace march in #turkey...   \n",
       "4  #mulcair suggests there’s bad blood between hi...   \n",
       "\n",
       "                                             Cleaned  \n",
       "0  [living, dream, ., #, cameraman, #, camera, #,...  \n",
       "1  [justin, #, trudeau, 's, reasons, thanksgiving...  \n",
       "2  [@, themadape, butt…..butt…..we, ’, allergic, ...  \n",
       "3  [2, massive, explosions, peace, march, #, turk...  \n",
       "4  [#, mulcair, suggests, ’, bad, blood, #, trude...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unclassf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [class, id, date, query, user, text, Cleaned]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# URL removal test for Classified tweets\n",
    "print(classf.loc[classf[\"text\"].str.contains('http')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [class, id, date, query, user, text, Cleaned]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [class, id, date, query, user, text, Cleaned]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [class, id, date, query, user, text, Cleaned]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# html-ASCII removal test for Classified tweets\n",
    "print(classf.loc[classf[\"text\"].str.contains('&amp')])\n",
    "print(classf.loc[classf[\"text\"].str.contains('&gt')])\n",
    "print(classf.loc[classf[\"text\"].str.contains('&quot')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Raw, Cleaned]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Raw, Cleaned]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# URL removal test for Unclassified tweets\n",
    "print(unclassf.loc[unclassf[\"Raw\"].str.contains('http')])\n",
    "print(unclassf.loc[unclassf[\"Raw\"].str.contains('www')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Raw, Cleaned]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Raw, Cleaned]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Raw, Cleaned]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# html-ASCII removal test for Unclassified tweets\n",
    "print(unclassf.loc[unclassf[\"Raw\"].str.contains('&amp')])\n",
    "print(unclassf.loc[unclassf[\"Raw\"].str.contains('&gt')])\n",
    "print(unclassf.loc[unclassf[\"Raw\"].str.contains('&quot')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# After removing stopwords from all tweets, join tokenized tweets for further analysis\n",
    "# Join tokenized texts\n",
    "def join(tweet):\n",
    "    tweet = \" \".join(tweet)\n",
    "    return tweet\n",
    "\n",
    "classf['Cleaned']  = classf['Cleaned'].apply(join)\n",
    "unclassf['Cleaned'] = unclassf['Cleaned'].apply(join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    @ switchfoot : // - awww , 's bummer . shoulda...\n",
       "1    upset ca n't update facebook texting might cry...\n",
       "2    @ kenichan dived many times ball . managed sav...\n",
       "3                     whole body feels itchy like fire\n",
       "4    @ nationwideclass , 's behaving . 'm mad . ? c...\n",
       "Name: Cleaned, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classf['Cleaned'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    living dream . # cameraman # camera # camerace...\n",
       "1    justin # trudeau 's reasons thanksgiving . tod...\n",
       "2    @ themadape butt…..butt…..we ’ allergic latex ...\n",
       "3    2 massive explosions peace march # turkey . 30...\n",
       "4    # mulcair suggests ’ bad blood # trudeau # rea...\n",
       "Name: Cleaned, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unclassf['Cleaned'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2. Exploratory Analysis (25 Marks)\n",
    "\n",
    "1. Design a simple procedure that determines the political party of a given tweet and apply this procedure to all the tweets in the unclassified dataset. \n",
    "\n",
    "    A suggestion would be to look at relevant words and hashtags in the tweets that identify to certain political parties. For example, tweets with  #trudeau correspond to tweets about the Liberal party. What can you say about the distribution of the political affiliations of the tweets?\n",
    "    \n",
    "    \n",
    "    \n",
    "2. Present a graphical figure (e.g. chart, graph, histogram, boxplot, word cloud, etc) that visualizes some aspect of the unclassified data and another figure for the classified data. All graphs and plots should be readable and have all axes that are appropriately labelled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indicators used for analysis\n",
    "#### Top 5 Canadian Political Parties in 2015 Canadian Federal election\n",
    "1. Liberal Party\n",
    " - leader: Justin Trudeau\n",
    " - Slogans: \"Real Change\"\n",
    " - key words: Justin, Trudeau, justintrudeau, realchange, #realchange,liberal\n",
    " \n",
    "2. Conservative Party\n",
    " - leader: Stephen Harper\n",
    " - Slogans: \"Safer canada\", \"Stronger Economy\", \"Protect our Economy\"\n",
    " - key words: Stephen, Harper, stephenharder, Safer, Safercanada, strongereconomy, protectoureconomy, conservative\n",
    " \n",
    "3. New Democratic\n",
    " - leader: Tom Mulcair\n",
    " - Slogans: \"Ready for change\"\n",
    " - key words: tom, mulcair, tommulcair, readyforchange , newdemocratic\n",
    " \n",
    "4. Bloc Quebeois\n",
    " - leader: Gilles Duceppe\n",
    " - Slogans: \n",
    " - key words: gilles, duceppe, gillesduceppe, blocquebeois, bloc, quebeois\n",
    "\n",
    "5. Green Party\n",
    " - leader: Elizabeth May\n",
    " - Slogans: \"A Canada That works Together\"\n",
    " - key words: elizabeth, elizabethmay, green, acanadathatworkstogether"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1. One-hot encode 'Classified_tweets' to find out relevant political parties based on key words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One-hot Encode Classified tweets\n",
    "# Creating separate columns for each party\n",
    "# Cell with 'True' might suggest the tweet is somehow relevant to the corresponding political party\n",
    "classf[\"Liberal\"] = classf['Cleaned'].str.contains('justin|trudeau|justintrudeau|liberal')\n",
    "classf[\"Conservative\"] = classf['Cleaned'].str.contains('stephen|harper|stephenharper|conservative')\n",
    "classf[\"NewDemocrat\"] = classf['Cleaned'].str.contains('tom|mulcair|tommulcair|newdemocratic')\n",
    "classf[\"BlocQueb\"] = classf['Cleaned'].str.contains('gilles|duceppe|gillesduceppe|blocquebeois')\n",
    "classf[\"Green\"] = classf['Cleaned'].str.contains('elizabeth|elizabethmay|green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liberal    231\n",
      "Name: Liberal, dtype: int64\n",
      "Conservative    335\n",
      "Name: Conservative, dtype: int64\n",
      "NewDemocrat    6386\n",
      "Name: NewDemocrat, dtype: int64\n",
      "BlocQueb    5\n",
      "Name: BlocQueb, dtype: int64\n",
      "Green    549\n",
      "Name: Green, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Data cleaning work\n",
    "# Replacing values for 'True' and 'False'\n",
    "# True = 'corresponding party name'\n",
    "# False = None\n",
    "# This cleaning process will also make plotting easier\n",
    "\n",
    "classf.loc[classf[\"Liberal\"] == True, \"Liberal\"] = 'Liberal'\n",
    "classf.loc[classf[\"Liberal\"] == False, \"Liberal\"] = None\n",
    "\n",
    "classf.loc[classf[\"Conservative\"] == True, \"Conservative\"] = 'Conservative'\n",
    "classf.loc[classf[\"Conservative\"] == False, \"Conservative\"] = None\n",
    "\n",
    "classf.loc[classf[\"NewDemocrat\"] == True, \"NewDemocrat\"] = 'NewDemocrat'\n",
    "classf.loc[classf[\"NewDemocrat\"] == False, \"NewDemocrat\"] = None\n",
    "\n",
    "classf.loc[classf[\"BlocQueb\"] == True, \"BlocQueb\"] = 'BlocQueb'\n",
    "classf.loc[classf[\"BlocQueb\"] == False, \"BlocQueb\"] = None\n",
    "\n",
    "classf.loc[classf[\"Green\"] == True, \"Green\"] = 'Green'\n",
    "classf.loc[classf[\"Green\"] == False, \"Green\"] = None\n",
    "\n",
    "# assign separate variable for each political party column\n",
    "liberal = classf[\"Liberal\"]\n",
    "conserv = classf[\"Conservative\"]\n",
    "ND = classf[\"NewDemocrat\"]\n",
    "BQ = classf[\"BlocQueb\"]\n",
    "green = classf[\"Green\"]\n",
    "\n",
    "# Counts for relevant tweets\n",
    "print(classf[\"Liberal\"].value_counts())\n",
    "print(classf[\"Conservative\"].value_counts())\n",
    "print(classf[\"NewDemocrat\"].value_counts())\n",
    "print(classf[\"BlocQueb\"].value_counts())\n",
    "print(classf[\"Green\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classified_Tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1954</th>\n",
       "      <td>Liberal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4941</th>\n",
       "      <td>Liberal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5481</th>\n",
       "      <td>Liberal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7258</th>\n",
       "      <td>Liberal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7691</th>\n",
       "      <td>Liberal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Classified_Tweets\n",
       "1954           Liberal\n",
       "4941           Liberal\n",
       "5481           Liberal\n",
       "7258           Liberal\n",
       "7691           Liberal"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate columns for different political parties for countplot\n",
    "classf_tweet_plot = pd.concat([liberal, conserv, ND, BQ, green])\n",
    "classf_tweet_plot.unique()\n",
    "ctp = pd.DataFrame(classf_tweet_plot, columns = ['Classified_Tweets'])\n",
    "\n",
    "# Return values != None\n",
    "ctp_new = ctp[ctp.Classified_Tweets.notnull()]\n",
    "ctp_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a280d8b70>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4UAAAJRCAYAAADyCBItAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngT8uMF0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116499550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Countplot for Classified tweets\n",
    "% matplotlib inline\n",
    "figure, ax1 = plt.subplots(nrows=1, ncols=1)\n",
    "figure.set_size_inches(15, 10)\n",
    "sns.countplot(data = ctp_new , x = 'Classified_Tweets', palette = 'Set2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2. One-hot encode 'Unclassified_tweets' to find out relevant political parties based on key words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One-hot encode Unclassified tweets\n",
    "unclassf[\"Liberal\"] = unclassf['Cleaned'].str.contains('justin|trudeau|justintrudeau|realchange|liberal')\n",
    "unclassf[\"Conservative\"] = unclassf['Cleaned'].str.contains('stephen|harper|stephenharper|safercanada|strongereconomy|protectoureconoomy|conservative')\n",
    "unclassf[\"NewDemocrat\"] = unclassf['Cleaned'].str.contains('tom|mulcair|tommulcair|readyforchange|newdemocratic')\n",
    "unclassf[\"BlocQueb\"] = unclassf['Cleaned'].str.contains('gilles|duceppe|gillesduceppe|blocquebeois|bloc|quebeois')\n",
    "unclassf[\"Green\"] = unclassf['Cleaned'].str.contains('elizabeth|elizabethmay|green|acanadathatworkstogether')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liberal    704\n",
      "Name: Liberal, dtype: int64\n",
      "Conservative    619\n",
      "Name: Conservative, dtype: int64\n",
      "NewDemocrat    302\n",
      "Name: NewDemocrat, dtype: int64\n",
      "BlocQueb    32\n",
      "Name: BlocQueb, dtype: int64\n",
      "Green    45\n",
      "Name: Green, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Data cleaning work\n",
    "# Replacing values for 'True' and 'False'\n",
    "# True = 'corresponding party name'\n",
    "# False = None\n",
    "# This cleaning process will also make plotting easier\n",
    "\n",
    "unclassf.loc[unclassf[\"Liberal\"] == True, \"Liberal\"] = 'Liberal'\n",
    "unclassf.loc[unclassf[\"Liberal\"] == False, \"Liberal\"] = None\n",
    "\n",
    "unclassf.loc[unclassf[\"Conservative\"] == True, \"Conservative\"] = 'Conservative'\n",
    "unclassf.loc[unclassf[\"Conservative\"] == False, \"Conservative\"] = None\n",
    "\n",
    "unclassf.loc[unclassf[\"NewDemocrat\"] == True, \"NewDemocrat\"] = 'NewDemocrat'\n",
    "unclassf.loc[unclassf[\"NewDemocrat\"] == False, \"NewDemocrat\"] = None\n",
    "\n",
    "unclassf.loc[unclassf[\"BlocQueb\"] == True, \"BlocQueb\"] = 'BlocQueb'\n",
    "unclassf.loc[unclassf[\"BlocQueb\"] == False, \"BlocQueb\"] = None\n",
    "\n",
    "unclassf.loc[unclassf[\"Green\"] == True, \"Green\"] = 'Green'\n",
    "unclassf.loc[unclassf[\"Green\"] == False, \"Green\"] = None\n",
    "\n",
    "# assign separate variable for each political party column\n",
    "unclassf_liberal = unclassf[\"Liberal\"]\n",
    "unclassf_conserv = unclassf[\"Conservative\"]\n",
    "unclassf_ND = unclassf[\"NewDemocrat\"]\n",
    "unclassf_BQ = unclassf[\"BlocQueb\"]\n",
    "unclassf_green = unclassf[\"Green\"]\n",
    "\n",
    "# Counts for relevant tweets\n",
    "print(unclassf[\"Liberal\"].value_counts())\n",
    "print(unclassf[\"Conservative\"].value_counts())\n",
    "print(unclassf[\"NewDemocrat\"].value_counts())\n",
    "print(unclassf[\"BlocQueb\"].value_counts())\n",
    "print(unclassf[\"Green\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unclassified_Tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Liberal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Liberal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Liberal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Liberal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Liberal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unclassified_Tweets\n",
       "1              Liberal\n",
       "4              Liberal\n",
       "5              Liberal\n",
       "8              Liberal\n",
       "10             Liberal"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate columns for different political parties for countplot\n",
    "unclassf_tweet_party = pd.concat([unclassf_liberal, unclassf_conserv, unclassf_ND, unclassf_BQ, unclassf_green])\n",
    "unclassf_tweet_party.unique()\n",
    "utp = pd.DataFrame(unclassf_tweet_party, columns = ['Unclassified_Tweets'])\n",
    "\n",
    "# Return values != None\n",
    "utp_new = utp[utp.Unclassified_Tweets.notnull()]\n",
    "utp_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a27f44e48>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA38AAAJRCAYAAAD1Zg59AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a279d1160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Countplot for Unclassified tweets\n",
    "figure, ax1 = plt.subplots(nrows=1, ncols=1)\n",
    "figure.set_size_inches(15,10)\n",
    "sns.countplot(data = utp_new, x = 'Unclassified_Tweets', palette = 'Set1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3. Model Preparation\n",
    "\n",
    "Split the classified data randomly into training data (70%) and test data (30%). \n",
    "\n",
    "Prepare the data for logistic regression where each tweet is considered a single observation. \n",
    "\n",
    "In the logistic regression model, the outcome variable is the sentiment value, which is either positive or negative. The independent variables or features of the model can be whatever you want. \n",
    "\n",
    "As a suggestion, you can use the frequency of each word as the features of the model, or alternatively, you can first tag each n-gram by its part of speech and then use the frequency of each part of speech as the features of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1. Splitting your training data into train & validation dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Cleaned</th>\n",
       "      <th>Liberal</th>\n",
       "      <th>Conservative</th>\n",
       "      <th>NewDemocrat</th>\n",
       "      <th>BlocQueb</th>\n",
       "      <th>Green</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@switchfoot :// - awww, that's a bummer.  you ...</td>\n",
       "      <td>@ switchfoot : // - awww , 's bummer . shoulda...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can't update his facebook by ...</td>\n",
       "      <td>upset ca n't update facebook texting might cry...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@kenichan i dived many times for the ball. man...</td>\n",
       "      <td>@ kenichan dived many times ball . managed sav...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>whole body feels itchy like fire</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>@ nationwideclass , 's behaving . 'm mad . ? c...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  @switchfoot :// - awww, that's a bummer.  you ...   \n",
       "1  is upset that he can't update his facebook by ...   \n",
       "2  @kenichan i dived many times for the ball. man...   \n",
       "3    my whole body feels itchy and like its on fire    \n",
       "4  @nationwideclass no, it's not behaving at all....   \n",
       "\n",
       "                                             Cleaned Liberal Conservative  \\\n",
       "0  @ switchfoot : // - awww , 's bummer . shoulda...    None         None   \n",
       "1  upset ca n't update facebook texting might cry...    None         None   \n",
       "2  @ kenichan dived many times ball . managed sav...    None         None   \n",
       "3                   whole body feels itchy like fire    None         None   \n",
       "4  @ nationwideclass , 's behaving . 'm mad . ? c...    None         None   \n",
       "\n",
       "  NewDemocrat BlocQueb Green  \n",
       "0        None     None  None  \n",
       "1        None     None  None  \n",
       "2        None     None  None  \n",
       "3        None     None  None  \n",
       "4        None     None  None  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, split the dataset into training input & label \n",
    "X = classf.iloc[:,5:]\n",
    "print(X.shape)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = classf.iloc[:,0]\n",
    "print(y.shape)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the classified tweet data randomly into training data (70%) and test data (30%). \n",
    "from sklearn.model_selection import train_test_split\n",
    "seed = 43\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140000, 7)\n",
      "(60000, 7)\n",
      "(140000,)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2. Use 'word' based Tfidvectorizer to create a term-frequency features to train a learning model\n",
    "##### Tfidf = 'term frequency–inverse document frequency'\n",
    "##### This will show how significant a word(or 'character' depending on hyperparameter) is to a text by calculating its frequency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=6923, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TfidVectorize ('word' based)\n",
    "# One of hyperparameters 'max_features' is set to 6923\n",
    "# This is because the maximum term-frequency feature that can be generated by unclassified_tweet is 6923\n",
    "# In order to make a prediction on unclassified_tweets, the number of features needs to be matching\n",
    "# Therefore, max_feature for Classified_tweets is also set to 6923\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(analyzer='word', max_features = 6923)\n",
    "vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140000, 6923)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<140000x6923 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 824791 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting here is vectorizing phrases, NOT the command for training your model !\n",
    "vectorizer.fit(X_train['Cleaned'])\n",
    "\n",
    "# After fitting, transform to matrix in order to make it trainable\n",
    "X_train_vec = vectorizer.transform(X_train['Cleaned'])\n",
    "print(X_train_vec.shape)\n",
    "X_train_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6923\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['00', '000', '00am', '03', '05']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use .get_feature_names() function to find out which terms you have as your features\n",
    "# This process is needed to make term-frequency feature matrix in the following step\n",
    "vocabulary = vectorizer.get_feature_names()\n",
    "\n",
    "print(len(vocabulary))\n",
    "vocabulary[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>00am</th>\n",
       "      <th>03</th>\n",
       "      <th>05</th>\n",
       "      <th>07</th>\n",
       "      <th>08</th>\n",
       "      <th>09</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>...</th>\n",
       "      <th>zero</th>\n",
       "      <th>zip</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zombies</th>\n",
       "      <th>zomg</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zzz</th>\n",
       "      <th>zzzz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6923 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00  000  00am   03   05   07   08   09   10  100  ...   zero  zip  zoe  \\\n",
       "0  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0  0.0   \n",
       "1  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0  0.0   \n",
       "2  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0  0.0   \n",
       "3  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0  0.0   \n",
       "4  0.0  0.0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0  0.0  0.0   \n",
       "\n",
       "   zombie  zombies  zomg  zone  zoo  zzz  zzzz  \n",
       "0     0.0      0.0   0.0   0.0  0.0  0.0   0.0  \n",
       "1     0.0      0.0   0.0   0.0  0.0  0.0   0.0  \n",
       "2     0.0      0.0   0.0   0.0  0.0  0.0   0.0  \n",
       "3     0.0      0.0   0.0   0.0  0.0  0.0   0.0  \n",
       "4     0.0      0.0   0.0   0.0  0.0  0.0   0.0  \n",
       "\n",
       "[5 rows x 6923 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shows Term frequency matrix\n",
    "pd.DataFrame(X_train_vec[0:100].toarray(), columns=vocabulary).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140000, 6923)\n",
      "(140000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_vec.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<60000x6923 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 350858 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No fitting for X_test because a learning model will be trained with X_train\n",
    "# However, X_test still needs to be transformed to a matrix to be able to be predicted.\n",
    "X_test_vec = vectorizer.transform(X_test['Cleaned'])\n",
    "X_test_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4. Model Implementation (15 Marks)\n",
    "Train a logistic regression model on the training data and apply the model to the test data\n",
    "to obtain an accuracy value. Evaluate the same model with the unclassified data.\n",
    "## 4-1. Training Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-1-1. Prediction on y_train (train error) & y_test (validation error) of Classified tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4, 4, 4, 4, 0, 4, 4, 0, 0, 4])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction on X_train_vec = train error\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "y_pred = cross_val_predict(model, X_train_vec, y_train, cv = 5)\n",
    "print(y_pred.shape)\n",
    "y_pred[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model on train dataset is 76.24000%\n"
     ]
    }
   ],
   "source": [
    "# Finding Train error\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "score_train_error = accuracy_score(y_train, y_pred)\n",
    "print('The accuracy of the model on train dataset is {0:.5f}%'.format(score_train_error*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit Logistic Regression model to make prediction on X_test_vec\n",
    "model.fit(X_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 4, 0, 4, 0, 4, 0, 4])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction on validation(30%) set within Classified_tweets\n",
    "prediction = model.predict(X_test_vec)\n",
    "prediction[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model on test dataset is 76.16000%\n"
     ]
    }
   ],
   "source": [
    "# Accuracy of prediction on validation(30%) set within Classified_tweets\n",
    "score_valid_error = accuracy_score(y_test, prediction)\n",
    "print('The accuracy of the model on test dataset is {0:.5f}%'.format(score_valid_error*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-1-2. Sentiment prediction on Unlassified tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Vectorize tweets to transform into term frequency matrix\n",
    "# vectorizer.fit(unclassf['Cleaned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3026x6923 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 10349 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same process with the test dataset of Classified_tweets\n",
    "# Just transforming to a matrix form in order to make it predictable by the model\n",
    "X_test_unclassf = vectorizer.transform(unclassf['Cleaned'])\n",
    "X_test_unclassf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4, 4, ..., 4, 4, 4])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run prediction on X_test of Unclassified tweet\n",
    "y_pred_unclassf = model.predict(X_test_unclassf)\n",
    "y_pred_unclassf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Raw</th>\n",
       "      <th>Cleaned</th>\n",
       "      <th>Liberal</th>\n",
       "      <th>Conservative</th>\n",
       "      <th>NewDemocrat</th>\n",
       "      <th>BlocQueb</th>\n",
       "      <th>Green</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>living the dream. #cameraman #camera #camerace...</td>\n",
       "      <td>living dream . # cameraman # camera # camerace...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NewDemocrat</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>justin #trudeau's reasons for thanksgiving. to...</td>\n",
       "      <td>justin # trudeau 's reasons thanksgiving . tod...</td>\n",
       "      <td>Liberal</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@themadape   butt…..butt…..we’re allergic to l...</td>\n",
       "      <td>@ themadape butt…..butt…..we ’ allergic latex ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2 massive explosions at peace march in #turkey...</td>\n",
       "      <td>2 massive explosions peace march # turkey . 30...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#mulcair suggests there’s bad blood between hi...</td>\n",
       "      <td># mulcair suggests ’ bad blood # trudeau # rea...</td>\n",
       "      <td>Liberal</td>\n",
       "      <td>None</td>\n",
       "      <td>NewDemocrat</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Raw  \\\n",
       "0  living the dream. #cameraman #camera #camerace...   \n",
       "1  justin #trudeau's reasons for thanksgiving. to...   \n",
       "2  @themadape   butt…..butt…..we’re allergic to l...   \n",
       "3  2 massive explosions at peace march in #turkey...   \n",
       "4  #mulcair suggests there’s bad blood between hi...   \n",
       "\n",
       "                                             Cleaned  Liberal Conservative  \\\n",
       "0  living dream . # cameraman # camera # camerace...     None         None   \n",
       "1  justin # trudeau 's reasons thanksgiving . tod...  Liberal         None   \n",
       "2  @ themadape butt…..butt…..we ’ allergic latex ...     None         None   \n",
       "3  2 massive explosions peace march # turkey . 30...     None         None   \n",
       "4  # mulcair suggests ’ bad blood # trudeau # rea...  Liberal         None   \n",
       "\n",
       "   NewDemocrat BlocQueb Green  class  \n",
       "0  NewDemocrat     None  None      0  \n",
       "1         None     None  None      4  \n",
       "2         None     None  None      4  \n",
       "3         None     None  None      0  \n",
       "4  NewDemocrat     None  None      0  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a column with class values in Unclassified_tweets dataset\n",
    "unclassf['class'] = y_pred_unclassf \n",
    "unclassf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5. Discussion (15 marks)\n",
    "Answer the research question stated above. Describe the results of the analysis and\n",
    "discuss your interpretation of the results. Did you gain any potential insights into the\n",
    "political sentiment of the Canadian electorate with respect to the major political parties\n",
    "participating in the 2015 federal election? Explain how each political party is viewed in\n",
    "the public eye based on the sentiment value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-1. counting negative & positive tweets for classified_tweets & unclassified_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>Cleaned</th>\n",
       "      <th>Liberal</th>\n",
       "      <th>Conservative</th>\n",
       "      <th>NewDemocrat</th>\n",
       "      <th>BlocQueb</th>\n",
       "      <th>Green</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100000</th>\n",
       "      <td>4</td>\n",
       "      <td>1467822272</td>\n",
       "      <td>Mon Apr 06 22:22:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ersle</td>\n",
       "      <td>i love @health4uandpets u guys r the best!!</td>\n",
       "      <td>love @ health4uandpets u guys r best ! !</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100001</th>\n",
       "      <td>4</td>\n",
       "      <td>1467822273</td>\n",
       "      <td>Mon Apr 06 22:22:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>becca210</td>\n",
       "      <td>im meeting up with one of my besties tonight! ...</td>\n",
       "      <td>im meeting one besties tonight ! cant wait ! !...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100002</th>\n",
       "      <td>4</td>\n",
       "      <td>1467822283</td>\n",
       "      <td>Mon Apr 06 22:22:46 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Wingman29</td>\n",
       "      <td>@darealsunisakim thanks for the twitter add, s...</td>\n",
       "      <td>@ darealsunisakim thanks twitter add , sunisa ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100003</th>\n",
       "      <td>4</td>\n",
       "      <td>1467822287</td>\n",
       "      <td>Mon Apr 06 22:22:46 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>katarinka</td>\n",
       "      <td>being sick can be really cheap when it hurts t...</td>\n",
       "      <td>sick really cheap hurts much eat real food plu...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100004</th>\n",
       "      <td>4</td>\n",
       "      <td>1467822293</td>\n",
       "      <td>Mon Apr 06 22:22:46 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_EmilyYoung</td>\n",
       "      <td>@lovesbrooklyn2 he has that effect on everyone</td>\n",
       "      <td>@ lovesbrooklyn2 effect everyone</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        class          id                          date     query  \\\n",
       "100000      4  1467822272  Mon Apr 06 22:22:45 PDT 2009  NO_QUERY   \n",
       "100001      4  1467822273  Mon Apr 06 22:22:45 PDT 2009  NO_QUERY   \n",
       "100002      4  1467822283  Mon Apr 06 22:22:46 PDT 2009  NO_QUERY   \n",
       "100003      4  1467822287  Mon Apr 06 22:22:46 PDT 2009  NO_QUERY   \n",
       "100004      4  1467822293  Mon Apr 06 22:22:46 PDT 2009  NO_QUERY   \n",
       "\n",
       "               user                                               text  \\\n",
       "100000        ersle       i love @health4uandpets u guys r the best!!    \n",
       "100001     becca210  im meeting up with one of my besties tonight! ...   \n",
       "100002    Wingman29  @darealsunisakim thanks for the twitter add, s...   \n",
       "100003    katarinka  being sick can be really cheap when it hurts t...   \n",
       "100004  _EmilyYoung    @lovesbrooklyn2 he has that effect on everyone    \n",
       "\n",
       "                                                  Cleaned Liberal  \\\n",
       "100000           love @ health4uandpets u guys r best ! !    None   \n",
       "100001  im meeting one besties tonight ! cant wait ! !...    None   \n",
       "100002  @ darealsunisakim thanks twitter add , sunisa ...    None   \n",
       "100003  sick really cheap hurts much eat real food plu...    None   \n",
       "100004                   @ lovesbrooklyn2 effect everyone    None   \n",
       "\n",
       "       Conservative NewDemocrat BlocQueb Green  \n",
       "100000         None        None     None  None  \n",
       "100001         None        None     None  None  \n",
       "100002         None        None     None  None  \n",
       "100003         None        None     None  None  \n",
       "100004         None        None     None  None  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counting positively analyzed tweets in Classified_tweets\n",
    "positive_classf = classf.loc[classf['class'] == 4]\n",
    "positive_classf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>Cleaned</th>\n",
       "      <th>Liberal</th>\n",
       "      <th>Conservative</th>\n",
       "      <th>NewDemocrat</th>\n",
       "      <th>BlocQueb</th>\n",
       "      <th>Green</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot :// - awww, that's a bummer.  you ...</td>\n",
       "      <td>@ switchfoot : // - awww , 's bummer . shoulda...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his facebook by ...</td>\n",
       "      <td>upset ca n't update facebook texting might cry...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@kenichan i dived many times for the ball. man...</td>\n",
       "      <td>@ kenichan dived many times ball . managed sav...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>whole body feels itchy like fire</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>@ nationwideclass , 's behaving . 'm mad . ? c...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class          id                          date     query             user  \\\n",
       "0      0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY  _TheSpecialOne_   \n",
       "1      0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY    scotthamilton   \n",
       "2      0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY         mattycus   \n",
       "3      0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          ElleCTF   \n",
       "4      0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY           Karoli   \n",
       "\n",
       "                                                text  \\\n",
       "0  @switchfoot :// - awww, that's a bummer.  you ...   \n",
       "1  is upset that he can't update his facebook by ...   \n",
       "2  @kenichan i dived many times for the ball. man...   \n",
       "3    my whole body feels itchy and like its on fire    \n",
       "4  @nationwideclass no, it's not behaving at all....   \n",
       "\n",
       "                                             Cleaned Liberal Conservative  \\\n",
       "0  @ switchfoot : // - awww , 's bummer . shoulda...    None         None   \n",
       "1  upset ca n't update facebook texting might cry...    None         None   \n",
       "2  @ kenichan dived many times ball . managed sav...    None         None   \n",
       "3                   whole body feels itchy like fire    None         None   \n",
       "4  @ nationwideclass , 's behaving . 'm mad . ? c...    None         None   \n",
       "\n",
       "  NewDemocrat BlocQueb Green  \n",
       "0        None     None  None  \n",
       "1        None     None  None  \n",
       "2        None     None  None  \n",
       "3        None     None  None  \n",
       "4        None     None  None  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counting negatively analyzed tweets in Classified_tweets\n",
    "negative_classf = classf.loc[classf['class'] == 0]\n",
    "negative_classf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liberal    135\n",
      "Name: Liberal, dtype: int64\n",
      "Conservative    183\n",
      "Name: Conservative, dtype: int64\n",
      "NewDemocrat    2651\n",
      "Name: NewDemocrat, dtype: int64\n",
      "BlocQueb    5\n",
      "Name: BlocQueb, dtype: int64\n",
      "Green    332\n",
      "Name: Green, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Number of positive counts\n",
    "print(positive_classf['Liberal'].value_counts())\n",
    "print(positive_classf['Conservative'].value_counts())\n",
    "print(positive_classf['NewDemocrat'].value_counts())\n",
    "print(positive_classf['BlocQueb'].value_counts())\n",
    "print(positive_classf['Green'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liberal    96\n",
      "Name: Liberal, dtype: int64\n",
      "Conservative    152\n",
      "Name: Conservative, dtype: int64\n",
      "NewDemocrat    3735\n",
      "Name: NewDemocrat, dtype: int64\n",
      "Series([], Name: BlocQueb, dtype: int64)\n",
      "Green    217\n",
      "Name: Green, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Number of negative counts\n",
    "print(negative_classf['Liberal'].value_counts())\n",
    "print(negative_classf['Conservative'].value_counts())\n",
    "print(negative_classf['NewDemocrat'].value_counts())\n",
    "print(negative_classf['BlocQueb'].value_counts())\n",
    "print(negative_classf['Green'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Raw</th>\n",
       "      <th>Cleaned</th>\n",
       "      <th>Liberal</th>\n",
       "      <th>Conservative</th>\n",
       "      <th>NewDemocrat</th>\n",
       "      <th>BlocQueb</th>\n",
       "      <th>Green</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>justin #trudeau's reasons for thanksgiving. to...</td>\n",
       "      <td>justin # trudeau 's reasons thanksgiving . tod...</td>\n",
       "      <td>Liberal</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@themadape   butt…..butt…..we’re allergic to l...</td>\n",
       "      <td>@ themadape butt…..butt…..we ’ allergic latex ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>#polqc on se sort de la marde avec #harper et ...</td>\n",
       "      <td># polqc se sort de la marde avec # harper et p...</td>\n",
       "      <td>Liberal</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>harper gave $8m to help other countries' get r...</td>\n",
       "      <td>harper gave $ 8m help countries ' get right wi...</td>\n",
       "      <td>None</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tommy taylor added,</td>\n",
       "      <td>tommy taylor added ,</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NewDemocrat</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Raw  \\\n",
       "1  justin #trudeau's reasons for thanksgiving. to...   \n",
       "2  @themadape   butt…..butt…..we’re allergic to l...   \n",
       "5  #polqc on se sort de la marde avec #harper et ...   \n",
       "6  harper gave $8m to help other countries' get r...   \n",
       "7                                tommy taylor added,   \n",
       "\n",
       "                                             Cleaned  Liberal  Conservative  \\\n",
       "1  justin # trudeau 's reasons thanksgiving . tod...  Liberal          None   \n",
       "2  @ themadape butt…..butt…..we ’ allergic latex ...     None          None   \n",
       "5  # polqc se sort de la marde avec # harper et p...  Liberal  Conservative   \n",
       "6  harper gave $ 8m help countries ' get right wi...     None  Conservative   \n",
       "7                               tommy taylor added ,     None          None   \n",
       "\n",
       "   NewDemocrat BlocQueb Green  class  \n",
       "1         None     None  None      4  \n",
       "2         None     None  None      4  \n",
       "5         None     None  None      4  \n",
       "6         None     None  None      4  \n",
       "7  NewDemocrat     None  None      4  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counting positively analyzed tweets in Unclassified_tweets\n",
    "positive_unclassf = unclassf.loc[unclassf['class'] == 4]\n",
    "positive_unclassf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Raw</th>\n",
       "      <th>Cleaned</th>\n",
       "      <th>Liberal</th>\n",
       "      <th>Conservative</th>\n",
       "      <th>NewDemocrat</th>\n",
       "      <th>BlocQueb</th>\n",
       "      <th>Green</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>living the dream. #cameraman #camera #camerace...</td>\n",
       "      <td>living dream . # cameraman # camera # camerace...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NewDemocrat</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2 massive explosions at peace march in #turkey...</td>\n",
       "      <td>2 massive explosions peace march # turkey . 30...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#mulcair suggests there’s bad blood between hi...</td>\n",
       "      <td># mulcair suggests ’ bad blood # trudeau # rea...</td>\n",
       "      <td>Liberal</td>\n",
       "      <td>None</td>\n",
       "      <td>NewDemocrat</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tracy s retweeted tsec</td>\n",
       "      <td>tracy retweeted tsec</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>it. pls canada, let's not keep a thug in offi...</td>\n",
       "      <td>. pls canada , let 's keep thug office destroy...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Raw  \\\n",
       "0   living the dream. #cameraman #camera #camerace...   \n",
       "3   2 massive explosions at peace march in #turkey...   \n",
       "4   #mulcair suggests there’s bad blood between hi...   \n",
       "9                             tracy s retweeted tsec    \n",
       "15   it. pls canada, let's not keep a thug in offi...   \n",
       "\n",
       "                                              Cleaned  Liberal Conservative  \\\n",
       "0   living dream . # cameraman # camera # camerace...     None         None   \n",
       "3   2 massive explosions peace march # turkey . 30...     None         None   \n",
       "4   # mulcair suggests ’ bad blood # trudeau # rea...  Liberal         None   \n",
       "9                                tracy retweeted tsec     None         None   \n",
       "15  . pls canada , let 's keep thug office destroy...     None         None   \n",
       "\n",
       "    NewDemocrat BlocQueb Green  class  \n",
       "0   NewDemocrat     None  None      0  \n",
       "3          None     None  None      0  \n",
       "4   NewDemocrat     None  None      0  \n",
       "9          None     None  None      0  \n",
       "15         None     None  None      0  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counting negatively analyzed tweets in Unclassified_tweets\n",
    "negative_unclassf = unclassf.loc[unclassf['class'] == 0]\n",
    "negative_unclassf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liberal    526\n",
      "Name: Liberal, dtype: int64\n",
      "Conservative    435\n",
      "Name: Conservative, dtype: int64\n",
      "NewDemocrat    224\n",
      "Name: NewDemocrat, dtype: int64\n",
      "BlocQueb    27\n",
      "Name: BlocQueb, dtype: int64\n",
      "Green    33\n",
      "Name: Green, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Number of positive counts\n",
    "print(positive_unclassf['Liberal'].value_counts())\n",
    "print(positive_unclassf['Conservative'].value_counts())\n",
    "print(positive_unclassf['NewDemocrat'].value_counts())\n",
    "print(positive_unclassf['BlocQueb'].value_counts())\n",
    "print(positive_unclassf['Green'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liberal    178\n",
      "Name: Liberal, dtype: int64\n",
      "Conservative    184\n",
      "Name: Conservative, dtype: int64\n",
      "NewDemocrat    78\n",
      "Name: NewDemocrat, dtype: int64\n",
      "BlocQueb    5\n",
      "Name: BlocQueb, dtype: int64\n",
      "Green    12\n",
      "Name: Green, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Number of negative counts\n",
    "print(negative_unclassf['Liberal'].value_counts())\n",
    "print(negative_unclassf['Conservative'].value_counts())\n",
    "print(negative_unclassf['NewDemocrat'].value_counts())\n",
    "print(negative_unclassf['BlocQueb'].value_counts())\n",
    "print(negative_unclassf['Green'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzed Data\n",
    "### A) Classified_tweets\n",
    "##### Number of positively analyzed tweets for each party: \n",
    "Liberal(135) |\n",
    "Conservative(183) |\n",
    "New Democrat(2651) |\n",
    "Bloc Quebois(5) |\n",
    "Green(332)\n",
    "    \n",
    "##### Number of negatively analyzed tweets for each party: \n",
    "Liberal(96) |\n",
    "Conservative(152) |\n",
    "New Democrat(3735) |\n",
    "Bloc Quebois(0) |\n",
    "Green(217)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### B) Unclassified_tweets\n",
    "##### Number of positively analyzed tweets for each party: Liberal(526) \n",
    "Liberal(526) |\n",
    "Conservative(435) | \n",
    "New Democrat(224) |\n",
    "Bloc Quebois(27) |\n",
    "Green(33)\n",
    "    \n",
    "##### Number of negatively analyzed tweets for each party:\n",
    "Liberal(178) | \n",
    "Conservative(184) | \n",
    "New Democrat(78) |\n",
    "Bloc Quebois(5) |\n",
    "Green(12)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### C) Actual Result of Canadian Federal Election 2015\n",
    "Liberal(39.5%) |\n",
    "Conservative(31.9%) |\n",
    "New Democrat(19.7%) |\n",
    "Bloc Quebois(4.7%) |\n",
    "Green(3.5%)\n",
    "\n",
    "Source: http://www.cbc.ca/news2/interactives/results-2015/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result of Analysis\n",
    "\n",
    "#### As a result of analysis of Classified_tweets, the data does not seem to be relevant to the actual result of 2015 Election. For both positively and negatively analyzed tweets have the most counts in New Democrat tweets followed by Conservative and Liberal. In conclusion, Classified_tweets is not a accurate enough dataset to begin with in terms of providing potential insights of the election.\n",
    "\n",
    "\n",
    "#### However, in the case of Unclassified_tweets, the result of tweet analysis shows fairly equivalent outcome to the actual result of the 2015 election. Among positively analyzed tweets, Liberal party has the most count, 526, followed by Conservative and New Democrat. This also corresponds to the actual result of the election in which Liberal had 39.5% of the vote, 31.9% for Conservative and 19.7% for New Democrat.\n",
    "\n",
    "#### In conclusion, the analysis tells us that Unclassified_tweet data is more appropriate and reliable data to work with in terms of giving insights for the prediction of 2015 election rather than Classified_tweet data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Hyperparameter Tuning\n",
    "\n",
    "1. Tune some of hyperparameters when vectorizing tweets: 'ngram_range'\n",
    "\n",
    "** n-gram refers to a contiguous sequence of n items from a given text.\n",
    "\n",
    "2. Increasing number of cv fold helped increainsg train accuracy (reducing train error) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=6923, min_df=1,\n",
       "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# By assigning ngram_range=(1,2), 2 words at maximum will be counted as one term while vectorizing each text\n",
    "# It is usally better to increase max_features as you increase ngram_range since there will be more verctorized 'terms'\n",
    "# However, max_feature value is kept the same due to the difference in data size between classified_tweets and unclassified_tweets\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(analyzer='word', max_features = 6923, ngram_range = (1,2))\n",
    "\n",
    "# vectorizer = TfidfVectorizer(analyzer='word', max_features = 6900)\n",
    "vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140000, 6923)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<140000x6923 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 894635 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectorize train data again with a new vectorizer with different ngram_range\n",
    "vectorizer.fit(X_train['Cleaned'])\n",
    "\n",
    "## After fitting, transform to matrix in order to make it trainable\n",
    "X_train_vec = vectorizer.transform(X_train['Cleaned'])\n",
    "print(X_train_vec.shape)\n",
    "X_train_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6923\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['00', '000', '000 followers', '05', '08']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use .get_feature_names() function to find out what features you have\n",
    "# This process is needed to make term feature - frequency matrix in the following step\n",
    "vocabulary = vectorizer.get_feature_names()\n",
    "\n",
    "print(len(vocabulary))\n",
    "vocabulary[0:5]\n",
    "# As you can see from the features above, features are different from previous vectorized tweets\n",
    "# Words are combined to make one feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000 followers</th>\n",
       "      <th>05</th>\n",
       "      <th>08</th>\n",
       "      <th>09</th>\n",
       "      <th>10</th>\n",
       "      <th>10 30</th>\n",
       "      <th>10 days</th>\n",
       "      <th>10 hours</th>\n",
       "      <th>...</th>\n",
       "      <th>zac</th>\n",
       "      <th>zac efron</th>\n",
       "      <th>zack</th>\n",
       "      <th>zackalltimelow</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zero</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zombies</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6923 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00  000  000 followers   05   08   09   10  10 30  10 days  10 hours ...   \\\n",
       "0  0.0  0.0            0.0  0.0  0.0  0.0  0.0    0.0      0.0       0.0 ...    \n",
       "1  0.0  0.0            0.0  0.0  0.0  0.0  0.0    0.0      0.0       0.0 ...    \n",
       "2  0.0  0.0            0.0  0.0  0.0  0.0  0.0    0.0      0.0       0.0 ...    \n",
       "3  0.0  0.0            0.0  0.0  0.0  0.0  0.0    0.0      0.0       0.0 ...    \n",
       "4  0.0  0.0            0.0  0.0  0.0  0.0  0.0    0.0      0.0       0.0 ...    \n",
       "\n",
       "   zac  zac efron  zack  zackalltimelow  zealand  zero  zombie  zombies  zone  \\\n",
       "0  0.0        0.0   0.0             0.0      0.0   0.0     0.0      0.0   0.0   \n",
       "1  0.0        0.0   0.0             0.0      0.0   0.0     0.0      0.0   0.0   \n",
       "2  0.0        0.0   0.0             0.0      0.0   0.0     0.0      0.0   0.0   \n",
       "3  0.0        0.0   0.0             0.0      0.0   0.0     0.0      0.0   0.0   \n",
       "4  0.0        0.0   0.0             0.0      0.0   0.0     0.0      0.0   0.0   \n",
       "\n",
       "   zoo  \n",
       "0  0.0  \n",
       "1  0.0  \n",
       "2  0.0  \n",
       "3  0.0  \n",
       "4  0.0  \n",
       "\n",
       "[5 rows x 6923 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shows Term frequency matrix\n",
    "pd.DataFrame(X_train_vec[0:100].toarray(), columns=vocabulary).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4, 4, 4, 4, 0, 0, 4, 0, 0, 4])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction on X_train_vec = train error\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "y_pred = cross_val_predict(model, X_train_vec, y_train, cv =15)\n",
    "print(y_pred.shape)\n",
    "y_pred[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model on train dataset is 76.62357%\n"
     ]
    }
   ],
   "source": [
    "# Train error\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "score_train_error = accuracy_score(y_train, y_pred)\n",
    "print('The accuracy of the model on train dataset is {0:.5f}%'.format(score_train_error*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train accuracy improved from 76.2400% to 76.62357%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 4, 0, 4, 0, 4, 0, 4])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction on validation(30%) set within Classified_tweets\n",
    "prediction = model.predict(X_test_vec)\n",
    "prediction[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model on test dataset is 76.16000%\n"
     ]
    }
   ],
   "source": [
    "# Accuracy of prediction on validation(30%) set within Classified_tweets\n",
    "score_valid_error = accuracy_score(y_test, prediction)\n",
    "print('The accuracy of the model on test dataset is {0:.5f}%'.format(score_valid_error*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "#### 1. Test accuracy stayed the same\n",
    "#### 2. Only showed improvement in lowering train error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Using SGDClassifier as a learning model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=73, shuffle=True,\n",
       "       tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "seed = 73\n",
    "model_class = SGDClassifier(random_state = seed)\n",
    "model_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keonpark/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=None, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=73, shuffle=True,\n",
       "       tol=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_class.fit(X_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 4, ..., 4, 4, 4])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_sgd = model_class.predict(X_test_vec)\n",
    "prediction_sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the SGDClassifier model on test dataset is 50.29500%\n"
     ]
    }
   ],
   "source": [
    "score_sgd = accuracy_score(y_test, prediction_sgd)\n",
    "print('The accuracy of the SGDClassifier model on test dataset is {0:.5f}%'.format(score_sgd*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result\n",
    "#### 1. Accuracy of SGDClassifer model is much lower than that of Logistic Regression(76.16%) --> Logistic Regression performs better on this particular data set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
